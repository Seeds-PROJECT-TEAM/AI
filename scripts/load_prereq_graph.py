# scripts/load_prereq_graph.py
from __future__ import annotations
import os, sys, csv, io, glob
from pathlib import Path
from dotenv import load_dotenv
from neo4j import GraphDatabase, exceptions as neo4j_exc

# â”€â”€ 0) í”„ë¡œì íŠ¸ ë£¨íŠ¸/ê²½ë¡œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROOT_DIR = Path(__file__).resolve().parents[1]        # .../AI
ENV_PATH = ROOT_DIR / ".env"
DATA_DIR = ROOT_DIR / "data"

# â”€â”€ 1) .env ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not ENV_PATH.exists():
    print(f"âŒ .env not found: {ENV_PATH}")
    sys.exit(1)
load_dotenv(ENV_PATH)

AURA_URI  = (os.getenv("AURA_URI") or "").strip()
AURA_USER = (os.getenv("AURA_USER") or "").strip()
AURA_PASS = (os.getenv("AURA_PASS") or "").strip()

def _require_env(k, v):
    if not v:
        print(f"âŒ Missing env: {k}")
        sys.exit(1)

_require_env("AURA_URI", AURA_URI)
_require_env("AURA_USER", AURA_USER)
_require_env("AURA_PASS", AURA_PASS)

# â”€â”€ 2) Neo4j ë“œë¼ì´ë²„ & ì—°ê²° í™•ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
driver = GraphDatabase.driver(AURA_URI, auth=(AURA_USER, AURA_PASS))
try:
    driver.verify_connectivity()
    print("âœ… Connected to Neo4j Aura")
except neo4j_exc.Neo4jError as e:
    print("âŒ Neo4j connectivity error:", e)
    sys.exit(1)

# â”€â”€ ìœ í‹¸: CSV ì¸ì½”ë”© ìë™ íŒë³„ + DictReader ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _open_csv_flex(path: Path):
    encodings = ["utf-8-sig", "utf-8", "cp949", "euc-kr", "latin1"]
    last_err = None
    for enc in encodings:
        try:
            f = open(path, "r", encoding=enc, newline="")
            reader = csv.DictReader(f)
            # fieldnames í‰ê°€(í—¤ë” í™•ì¸)
            if not reader.fieldnames:
                raise ValueError("No header found")
            # BOM ì œê±°/ì •ê·œí™” ì¬ì‹œì‘
            f.seek(0)
            return f, enc
        except Exception as e:
            last_err = e
            try:
                f.close()
            except:
                pass
    raise RuntimeError(f"CSV ì¸ì½”ë”© íŒë³„ ì‹¤íŒ¨: {path} ({last_err})")

def _norm_row_keys(d: dict):
    return { (k.lstrip("\ufeff").strip().lower() if isinstance(k, str) else k): v
             for k, v in d.items() }

# â”€â”€ 3) ìŠ¤í‚¤ë§ˆ ì œì•½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def create_constraints():
    with driver.session() as s:
        s.run("""
        CREATE CONSTRAINT concept_name IF NOT EXISTS
        FOR (c:Concept) REQUIRE c.name IS UNIQUE
        """)
    print("ğŸ”§ Constraint ensured: Concept.name UNIQUE")

# â”€â”€ 4) ì ì¬ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_nodes(csv_path: Path):
    if not csv_path.exists():
        print(f"âŒ nodes CSV not found: {csv_path}")
        sys.exit(1)
    f, enc_used = _open_csv_flex(csv_path)
    print(f"ğŸ“„ Nodes CSV encoding detected: {enc_used}")
    with driver.session() as s, f:
        reader = csv.DictReader(f)
        cnt = 0
        for raw in reader:
            row = _norm_row_keys(raw)
            name  = row.get("concept") or row.get("name")
            unit  = row.get("unit") or ""
            grade = row.get("grade") or ""
            if not name:
                continue
            s.run("""
            MERGE (c:Concept {name:$name})
            SET c.unit = CASE WHEN $unit<>'' THEN $unit ELSE c.unit END,
                c.grade = CASE WHEN $grade<>'' THEN $grade ELSE c.grade END
            """, name=name, unit=unit, grade=grade)
            cnt += 1
    print(f"â¬†ï¸  Nodes upserted: {cnt}")

def load_edges(csv_path: Path):
    if not csv_path.exists():
        # neo4j_edges (1).csv ê°™ì€ íŒŒì¼ ìë™ íƒìƒ‰
        candidates = sorted(DATA_DIR.glob("neo4j_edges*.csv"))
        if candidates:
            print(f"â„¹ï¸ edges CSV not found at '{csv_path.name}', using '{candidates[0].name}'")
            csv_path = candidates[0]
        else:
            print(f"âŒ edges CSV not found: {csv_path}")
            sys.exit(1)
    f, enc_used = _open_csv_flex(csv_path)
    print(f"ğŸ“„ Edges CSV encoding detected: {enc_used} ({csv_path.name})")
    with driver.session() as s, f:
        reader = csv.DictReader(f)
        cnt = 0
        for raw in reader:
            row = _norm_row_keys(raw)
            src = row.get("source") or row.get("src")
            dst = row.get("target") or row.get("dst")
            if not src or not dst:
                continue
            s.run("""
            MERGE (src:Concept {name:$src})
            MERGE (dst:Concept {name:$dst})
            MERGE (src)-[:PRECEDES]->(dst)
            """, src=src, dst=dst)
            cnt += 1
    print(f"ğŸ”— Edges upserted: {cnt}")

# â”€â”€ 5) ì‹¤í–‰ ì§„ì…ì  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    nodes_csv = DATA_DIR / "neo4j_nodes.csv"
    edges_csv = DATA_DIR / "neo4j_edges.csv"  # ê¸°ë³¸ ì´ë¦„. ì—†ìœ¼ë©´ globë¡œ ëŒ€ì²´ë¨

    create_constraints()
    load_nodes(nodes_csv)
    load_edges(edges_csv)
    driver.close()
    print("ğŸ Done: Neo4j Aura ì ì¬ ì™„ë£Œ")
